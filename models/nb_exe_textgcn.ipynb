{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-28T19:04:58.706633Z",
     "start_time": "2025-03-28T19:04:40.022986Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from build_graph import BuildGraph\n",
    "from py_gcn import GCN\n",
    "import torch.nn.functional as F\n",
    "import torch \n",
    "import time\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T19:05:13.985115Z",
     "start_time": "2025-03-28T19:04:58.710019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build Graph\n",
    "g = BuildGraph(\"UIT_VFSC\").g\n",
    "print(g)"
   ],
   "id": "ac22c5969e4acf4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step pre processing\n",
      "step add word doc edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 16175it [00:02, 5528.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step add word word edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing word pair count frequency: 100%|██████████| 87309/87309 [00:04<00:00, 21045.41it/s]\n",
      "Adding word_word edges: 100%|██████████| 337534/337534 [00:00<00:00, 408558.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step setup graph\n",
      "Graph(num_nodes=19020, num_edges=595385,\n",
      "      ndata_schemes={'x': Scheme(shape=(2845,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float32)})\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T19:05:14.005694Z",
     "start_time": "2025-03-28T19:05:13.986680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "node_features = g.ndata['x']\n",
    "node_labels = g.ndata['label']\n",
    "train_mask = g.ndata['train_mask']\n",
    "test_mask = g.ndata['test_mask']\n",
    "n_features = node_features.shape[1]\n",
    "n_labels = int(node_labels.max().item() + 1)\n",
    "print(n_features)\n",
    "print(node_features.shape)"
   ],
   "id": "2d868205c975682f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2845\n",
      "torch.Size([19020, 2845])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T19:05:14.015464Z",
     "start_time": "2025-03-28T19:05:14.006703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate model\n",
    "def evaluate(model, graph, features, labels, mask, edge_weights=None):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        logits = model(features, graph, edge_weights)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "\n",
    "        correct = torch.sum(indices == labels)\n",
    "\n",
    "        acc = correct.item() * 1.0 / len(labels)\n",
    "        mf1 = multiclass_f1_score(indices.type(torch.long), labels.type(torch.long), num_classes=n_labels, average='macro')\n",
    "        wf1 = multiclass_f1_score(indices.type(torch.long), labels.type(torch.long), num_classes=n_labels, average='weighted')\n",
    "\n",
    "        return acc, mf1, wf1"
   ],
   "id": "802a006fd204160e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T19:05:14.041207Z",
     "start_time": "2025-03-28T19:05:14.020452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build Model\n",
    "model = GCN(\n",
    "            in_feats=n_features,\n",
    "            n_hidden=200,\n",
    "            n_classes=n_labels,\n",
    "            n_layers=1,\n",
    "            activation=F.elu,\n",
    "            dropout=0.5\n",
    "        )\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-3)"
   ],
   "id": "344994dc4b61953a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T19:10:15.605590Z",
     "start_time": "2025-03-28T19:05:14.042709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# training model\n",
    "dur = []\n",
    "max_acc = 0\n",
    "max_f1 = 0\n",
    "for epoch in range(1000):\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "    model.train()\n",
    "    # forward propagation by using all nodes\n",
    "    logits = model(node_features, g, g.edata['weight'])\n",
    "    \n",
    "    # compute loss\n",
    "    loss = F.cross_entropy(logits[train_mask].to(torch.float32), node_labels[train_mask].to(torch.long))\n",
    "\n",
    "    # backward propagation\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    # compute validation accuracy\n",
    "    acc, mf1, wf1 = evaluate(model, g, node_features, node_labels, test_mask, g.edata['weight'])\n",
    "    print(f\"Epoch {epoch:05d} | Loss {loss.item():.4f} | Test Acc {acc:.4f} | mF1 {mf1:.4f} | wF1 {wf1:.4f} | Time(s) {np.mean(dur):.4f}\")\n",
    "\n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "    max_f1 = max(max(max_f1, wf1), mf1)\n"
   ],
   "id": "162f8f215122fe26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 2.2434 | Test Acc 0.4570 | mF1 0.2226 | wF1 0.2999 | Time(s) nan\n",
      "Epoch 00001 | Loss 11.5292 | Test Acc 0.5411 | mF1 0.3273 | wF1 0.4554 | Time(s) nan\n",
      "Epoch 00002 | Loss 9.7142 | Test Acc 0.6608 | mF1 0.4424 | wF1 0.6251 | Time(s) nan\n",
      "Epoch 00003 | Loss 7.2514 | Test Acc 0.7527 | mF1 0.5148 | wF1 0.7311 | Time(s) 1.0434\n",
      "Epoch 00004 | Loss 5.1819 | Test Acc 0.7745 | mF1 0.5303 | wF1 0.7543 | Time(s) 1.0460\n",
      "Epoch 00005 | Loss 4.4022 | Test Acc 0.7432 | mF1 0.5048 | wF1 0.7196 | Time(s) 1.0296\n",
      "Epoch 00006 | Loss 4.9085 | Test Acc 0.7227 | mF1 0.4861 | wF1 0.6941 | Time(s) 1.0245\n",
      "Epoch 00007 | Loss 5.9783 | Test Acc 0.7344 | mF1 0.4957 | wF1 0.7074 | Time(s) 1.0131\n",
      "Epoch 00008 | Loss 5.4559 | Test Acc 0.7517 | mF1 0.5112 | wF1 0.7285 | Time(s) 1.0324\n",
      "Epoch 00009 | Loss 5.1341 | Test Acc 0.7735 | mF1 0.5286 | wF1 0.7525 | Time(s) 1.0299\n",
      "Epoch 00010 | Loss 4.5637 | Test Acc 0.7836 | mF1 0.5365 | wF1 0.7633 | Time(s) 1.0324\n",
      "Epoch 00011 | Loss 4.2856 | Test Acc 0.7843 | mF1 0.5372 | wF1 0.7639 | Time(s) 1.0338\n",
      "Epoch 00012 | Loss 4.3206 | Test Acc 0.7805 | mF1 0.5346 | wF1 0.7599 | Time(s) 1.0320\n",
      "Epoch 00013 | Loss 4.4365 | Test Acc 0.7814 | mF1 0.5353 | wF1 0.7608 | Time(s) 1.0348\n",
      "Epoch 00014 | Loss 4.5240 | Test Acc 0.7827 | mF1 0.5361 | wF1 0.7619 | Time(s) 1.0346\n",
      "Epoch 00015 | Loss 4.5817 | Test Acc 0.7821 | mF1 0.5356 | wF1 0.7612 | Time(s) 1.0367\n",
      "Epoch 00016 | Loss 4.5054 | Test Acc 0.7840 | mF1 0.5369 | wF1 0.7631 | Time(s) 1.0362\n",
      "Epoch 00017 | Loss 4.5691 | Test Acc 0.7849 | mF1 0.5376 | wF1 0.7641 | Time(s) 1.0394\n",
      "Epoch 00018 | Loss 4.3817 | Test Acc 0.7884 | mF1 0.5400 | wF1 0.7676 | Time(s) 1.0350\n",
      "Epoch 00019 | Loss 4.3159 | Test Acc 0.7915 | mF1 0.5422 | wF1 0.7708 | Time(s) 1.0346\n",
      "Epoch 00020 | Loss 4.2205 | Test Acc 0.7966 | mF1 0.5456 | wF1 0.7759 | Time(s) 1.0397\n",
      "Epoch 00021 | Loss 4.0094 | Test Acc 0.7994 | mF1 0.5475 | wF1 0.7787 | Time(s) 1.0412\n",
      "Epoch 00022 | Loss 3.9051 | Test Acc 0.8032 | mF1 0.5498 | wF1 0.7821 | Time(s) 1.0460\n",
      "Epoch 00023 | Loss 3.9451 | Test Acc 0.8039 | mF1 0.5500 | wF1 0.7825 | Time(s) 1.0467\n",
      "Epoch 00024 | Loss 3.9077 | Test Acc 0.8035 | mF1 0.5495 | wF1 0.7819 | Time(s) 1.0473\n",
      "Epoch 00025 | Loss 4.0239 | Test Acc 0.8039 | mF1 0.5496 | wF1 0.7821 | Time(s) 1.0470\n",
      "Epoch 00026 | Loss 3.7822 | Test Acc 0.8054 | mF1 0.5507 | wF1 0.7837 | Time(s) 1.0475\n",
      "Epoch 00027 | Loss 4.0465 | Test Acc 0.8111 | mF1 0.5549 | wF1 0.7894 | Time(s) 1.0487\n",
      "Epoch 00028 | Loss 3.7036 | Test Acc 0.8146 | mF1 0.5574 | wF1 0.7930 | Time(s) 1.0484\n",
      "Epoch 00029 | Loss 3.6773 | Test Acc 0.8168 | mF1 0.5591 | wF1 0.7953 | Time(s) 1.0491\n",
      "Epoch 00030 | Loss 3.5535 | Test Acc 0.8168 | mF1 0.5593 | wF1 0.7954 | Time(s) 1.0555\n",
      "Epoch 00031 | Loss 3.4100 | Test Acc 0.8219 | mF1 0.5628 | wF1 0.8004 | Time(s) 1.0562\n",
      "Epoch 00032 | Loss 3.3731 | Test Acc 0.8228 | mF1 0.5635 | wF1 0.8013 | Time(s) 1.0581\n",
      "Epoch 00033 | Loss 3.3512 | Test Acc 0.8238 | mF1 0.5641 | wF1 0.8023 | Time(s) 1.0588\n",
      "Epoch 00034 | Loss 3.3497 | Test Acc 0.8269 | mF1 0.5663 | wF1 0.8053 | Time(s) 1.0597\n",
      "Epoch 00035 | Loss 3.1360 | Test Acc 0.8320 | mF1 0.5696 | wF1 0.8101 | Time(s) 1.0588\n",
      "Epoch 00036 | Loss 3.1248 | Test Acc 0.8364 | mF1 0.5725 | wF1 0.8142 | Time(s) 1.0571\n",
      "Epoch 00037 | Loss 2.9425 | Test Acc 0.8351 | mF1 0.5714 | wF1 0.8128 | Time(s) 1.0572\n",
      "Epoch 00038 | Loss 3.0296 | Test Acc 0.8339 | mF1 0.5704 | wF1 0.8114 | Time(s) 1.0568\n",
      "Epoch 00039 | Loss 2.9331 | Test Acc 0.8358 | mF1 0.5717 | wF1 0.8132 | Time(s) 1.0560\n",
      "Epoch 00040 | Loss 3.0325 | Test Acc 0.8389 | mF1 0.5740 | wF1 0.8164 | Time(s) 1.0567\n",
      "Epoch 00041 | Loss 2.8329 | Test Acc 0.8424 | mF1 0.5766 | wF1 0.8199 | Time(s) 1.0551\n",
      "Epoch 00042 | Loss 2.6536 | Test Acc 0.8440 | mF1 0.5778 | wF1 0.8216 | Time(s) 1.0555\n",
      "Epoch 00043 | Loss 2.6441 | Test Acc 0.8446 | mF1 0.5783 | wF1 0.8224 | Time(s) 1.0556\n",
      "Epoch 00044 | Loss 2.6478 | Test Acc 0.8462 | mF1 0.5794 | wF1 0.8239 | Time(s) 1.0560\n",
      "Epoch 00045 | Loss 2.5894 | Test Acc 0.8493 | mF1 0.5815 | wF1 0.8268 | Time(s) 1.0567\n",
      "Epoch 00046 | Loss 2.5285 | Test Acc 0.8503 | mF1 0.5821 | wF1 0.8277 | Time(s) 1.0572\n",
      "Epoch 00047 | Loss 2.4973 | Test Acc 0.8563 | mF1 0.5861 | wF1 0.8334 | Time(s) 1.0552\n",
      "Epoch 00048 | Loss 2.4365 | Test Acc 0.8563 | mF1 0.5860 | wF1 0.8333 | Time(s) 1.0550\n",
      "Epoch 00049 | Loss 2.2987 | Test Acc 0.8579 | mF1 0.5870 | wF1 0.8347 | Time(s) 1.0532\n",
      "Epoch 00050 | Loss 2.4559 | Test Acc 0.8613 | mF1 0.5895 | wF1 0.8381 | Time(s) 1.0517\n",
      "Epoch 00051 | Loss 2.3182 | Test Acc 0.8639 | mF1 0.5913 | wF1 0.8407 | Time(s) 1.0504\n",
      "Epoch 00052 | Loss 2.2442 | Test Acc 0.8642 | mF1 0.5916 | wF1 0.8410 | Time(s) 1.0499\n",
      "Epoch 00053 | Loss 2.1896 | Test Acc 0.8670 | mF1 0.5935 | wF1 0.8438 | Time(s) 1.0492\n",
      "Epoch 00054 | Loss 2.1513 | Test Acc 0.8680 | mF1 0.5942 | wF1 0.8447 | Time(s) 1.0484\n",
      "Epoch 00055 | Loss 2.1540 | Test Acc 0.8680 | mF1 0.5942 | wF1 0.8446 | Time(s) 1.0463\n",
      "Epoch 00056 | Loss 2.0742 | Test Acc 0.8670 | mF1 0.5935 | wF1 0.8436 | Time(s) 1.0455\n",
      "Epoch 00057 | Loss 2.0913 | Test Acc 0.8664 | mF1 0.5930 | wF1 0.8430 | Time(s) 1.0443\n",
      "Epoch 00058 | Loss 2.0462 | Test Acc 0.8689 | mF1 0.5948 | wF1 0.8455 | Time(s) 1.0440\n",
      "Epoch 00059 | Loss 1.9568 | Test Acc 0.8708 | mF1 0.5961 | wF1 0.8473 | Time(s) 1.0449\n",
      "Epoch 00060 | Loss 1.9711 | Test Acc 0.8724 | mF1 0.5972 | wF1 0.8489 | Time(s) 1.0430\n",
      "Epoch 00061 | Loss 1.8804 | Test Acc 0.8743 | mF1 0.5985 | wF1 0.8508 | Time(s) 1.0440\n",
      "Epoch 00062 | Loss 1.9137 | Test Acc 0.8727 | mF1 0.5975 | wF1 0.8494 | Time(s) 1.0439\n",
      "Epoch 00063 | Loss 1.9665 | Test Acc 0.8727 | mF1 0.5974 | wF1 0.8491 | Time(s) 1.0444\n",
      "Epoch 00064 | Loss 1.8133 | Test Acc 0.8654 | mF1 0.5924 | wF1 0.8419 | Time(s) 1.0442\n",
      "Epoch 00065 | Loss 1.8465 | Test Acc 0.8654 | mF1 0.5924 | wF1 0.8419 | Time(s) 1.0444\n",
      "Epoch 00066 | Loss 1.8186 | Test Acc 0.8724 | mF1 0.5972 | wF1 0.8488 | Time(s) 1.0435\n",
      "Epoch 00067 | Loss 1.7708 | Test Acc 0.8778 | mF1 0.6009 | wF1 0.8542 | Time(s) 1.0430\n",
      "Epoch 00068 | Loss 1.8706 | Test Acc 0.8749 | mF1 0.5989 | wF1 0.8513 | Time(s) 1.0428\n",
      "Epoch 00069 | Loss 1.7193 | Test Acc 0.8730 | mF1 0.5976 | wF1 0.8494 | Time(s) 1.0426\n",
      "Epoch 00070 | Loss 1.6771 | Test Acc 0.8692 | mF1 0.5950 | wF1 0.8456 | Time(s) 1.0423\n",
      "Epoch 00071 | Loss 1.7524 | Test Acc 0.8743 | mF1 0.5985 | wF1 0.8507 | Time(s) 1.0413\n",
      "Epoch 00072 | Loss 1.6208 | Test Acc 0.8749 | mF1 0.5990 | wF1 0.8516 | Time(s) 1.0411\n",
      "Epoch 00073 | Loss 1.6403 | Test Acc 0.8746 | mF1 0.5988 | wF1 0.8512 | Time(s) 1.0405\n",
      "Epoch 00074 | Loss 1.6447 | Test Acc 0.8756 | mF1 0.5994 | wF1 0.8519 | Time(s) 1.0404\n",
      "Epoch 00075 | Loss 1.5330 | Test Acc 0.8727 | mF1 0.5974 | wF1 0.8490 | Time(s) 1.0396\n",
      "Epoch 00076 | Loss 1.5280 | Test Acc 0.8724 | mF1 0.5972 | wF1 0.8488 | Time(s) 1.0390\n",
      "Epoch 00077 | Loss 1.5055 | Test Acc 0.8746 | mF1 0.5988 | wF1 0.8511 | Time(s) 1.0386\n",
      "Epoch 00078 | Loss 1.5125 | Test Acc 0.8721 | mF1 0.5971 | wF1 0.8488 | Time(s) 1.0388\n",
      "Epoch 00079 | Loss 1.4926 | Test Acc 0.8774 | mF1 0.6007 | wF1 0.8538 | Time(s) 1.0388\n",
      "Epoch 00080 | Loss 1.4304 | Test Acc 0.8711 | mF1 0.5964 | wF1 0.8475 | Time(s) 1.0388\n",
      "Epoch 00081 | Loss 1.4667 | Test Acc 0.8733 | mF1 0.5979 | wF1 0.8497 | Time(s) 1.0391\n",
      "Epoch 00082 | Loss 1.3987 | Test Acc 0.8636 | mF1 0.5913 | wF1 0.8405 | Time(s) 1.0394\n",
      "Epoch 00083 | Loss 1.4638 | Test Acc 0.8721 | mF1 0.5971 | wF1 0.8486 | Time(s) 1.0397\n",
      "Epoch 00084 | Loss 1.4325 | Test Acc 0.8500 | mF1 0.5815 | wF1 0.8266 | Time(s) 1.0396\n",
      "Epoch 00085 | Loss 1.4086 | Test Acc 0.8449 | mF1 0.5778 | wF1 0.8215 | Time(s) 1.0398\n",
      "Epoch 00086 | Loss 1.5372 | Test Acc 0.8756 | mF1 0.5993 | wF1 0.8520 | Time(s) 1.0403\n",
      "Epoch 00087 | Loss 1.3272 | Test Acc 0.8572 | mF1 0.5870 | wF1 0.8346 | Time(s) 1.0398\n",
      "Epoch 00088 | Loss 1.5730 | Test Acc 0.8613 | mF1 0.5898 | wF1 0.8385 | Time(s) 1.0390\n",
      "Epoch 00089 | Loss 1.4884 | Test Acc 0.8714 | mF1 0.5964 | wF1 0.8479 | Time(s) 1.0391\n",
      "Epoch 00090 | Loss 1.4116 | Test Acc 0.8557 | mF1 0.5854 | wF1 0.8322 | Time(s) 1.0391\n",
      "Epoch 00091 | Loss 1.3098 | Test Acc 0.8459 | mF1 0.5783 | wF1 0.8223 | Time(s) 1.0389\n",
      "Epoch 00092 | Loss 1.5168 | Test Acc 0.8743 | mF1 0.5984 | wF1 0.8506 | Time(s) 1.0384\n",
      "Epoch 00093 | Loss 1.3263 | Test Acc 0.8718 | mF1 0.5969 | wF1 0.8486 | Time(s) 1.0382\n",
      "Epoch 00094 | Loss 1.3544 | Test Acc 0.8604 | mF1 0.5892 | wF1 0.8376 | Time(s) 1.0375\n",
      "Epoch 00095 | Loss 1.4549 | Test Acc 0.8733 | mF1 0.5980 | wF1 0.8499 | Time(s) 1.0371\n",
      "Epoch 00096 | Loss 1.2580 | Test Acc 0.8749 | mF1 0.5990 | wF1 0.8512 | Time(s) 1.0367\n",
      "Epoch 00097 | Loss 1.2197 | Test Acc 0.8610 | mF1 0.5893 | wF1 0.8375 | Time(s) 1.0363\n",
      "Epoch 00098 | Loss 1.3303 | Test Acc 0.8737 | mF1 0.5981 | wF1 0.8500 | Time(s) 1.0366\n",
      "Epoch 00099 | Loss 1.2189 | Test Acc 0.8762 | mF1 0.5999 | wF1 0.8525 | Time(s) 1.0369\n",
      "Epoch 00100 | Loss 1.2000 | Test Acc 0.8737 | mF1 0.5982 | wF1 0.8500 | Time(s) 1.0364\n",
      "Epoch 00101 | Loss 1.2096 | Test Acc 0.8740 | mF1 0.5984 | wF1 0.8504 | Time(s) 1.0363\n",
      "Epoch 00102 | Loss 1.1461 | Test Acc 0.8762 | mF1 0.5999 | wF1 0.8525 | Time(s) 1.0355\n",
      "Epoch 00103 | Loss 1.1767 | Test Acc 0.8714 | mF1 0.5966 | wF1 0.8478 | Time(s) 1.0351\n",
      "Epoch 00104 | Loss 1.1535 | Test Acc 0.8677 | mF1 0.5939 | wF1 0.8441 | Time(s) 1.0350\n",
      "Epoch 00105 | Loss 1.2410 | Test Acc 0.8740 | mF1 0.5984 | wF1 0.8506 | Time(s) 1.0350\n",
      "Epoch 00106 | Loss 1.1262 | Test Acc 0.8553 | mF1 0.5859 | wF1 0.8330 | Time(s) 1.0353\n",
      "Epoch 00107 | Loss 1.2458 | Test Acc 0.8651 | mF1 0.5925 | wF1 0.8424 | Time(s) 1.0350\n",
      "Epoch 00108 | Loss 1.1346 | Test Acc 0.8765 | mF1 0.6002 | wF1 0.8531 | Time(s) 1.0354\n",
      "Epoch 00109 | Loss 1.1008 | Test Acc 0.8661 | mF1 0.5929 | wF1 0.8426 | Time(s) 1.0351\n",
      "Epoch 00110 | Loss 1.0789 | Test Acc 0.8424 | mF1 0.5800 | wF1 0.8196 | Time(s) 1.0350\n",
      "Epoch 00111 | Loss 1.0859 | Test Acc 0.8531 | mF1 0.5951 | wF1 0.8312 | Time(s) 1.0346\n",
      "Epoch 00112 | Loss 1.1507 | Test Acc 0.8778 | mF1 0.6161 | wF1 0.8563 | Time(s) 1.0342\n",
      "Epoch 00113 | Loss 1.0106 | Test Acc 0.8673 | mF1 0.6091 | wF1 0.8465 | Time(s) 1.0338\n",
      "Epoch 00114 | Loss 1.0457 | Test Acc 0.8702 | mF1 0.6146 | wF1 0.8497 | Time(s) 1.0332\n",
      "Epoch 00115 | Loss 0.9649 | Test Acc 0.8778 | mF1 0.6548 | wF1 0.8619 | Time(s) 1.0330\n",
      "Epoch 00116 | Loss 0.7680 | Test Acc 0.8541 | mF1 0.6763 | wF1 0.8557 | Time(s) 1.0336\n",
      "Epoch 00117 | Loss 0.6325 | Test Acc 0.7896 | mF1 0.6489 | wF1 0.8197 | Time(s) 1.0342\n",
      "Epoch 00118 | Loss 0.9143 | Test Acc 0.8667 | mF1 0.6778 | wF1 0.8611 | Time(s) 1.0336\n",
      "Epoch 00119 | Loss 0.5666 | Test Acc 0.8809 | mF1 0.6569 | wF1 0.8648 | Time(s) 1.0334\n",
      "Epoch 00120 | Loss 0.6586 | Test Acc 0.8806 | mF1 0.6420 | wF1 0.8621 | Time(s) 1.0330\n",
      "Epoch 00121 | Loss 0.6776 | Test Acc 0.8809 | mF1 0.6356 | wF1 0.8616 | Time(s) 1.0324\n",
      "Epoch 00122 | Loss 0.6940 | Test Acc 0.8809 | mF1 0.6322 | wF1 0.8611 | Time(s) 1.0323\n",
      "Epoch 00123 | Loss 0.6298 | Test Acc 0.8825 | mF1 0.6589 | wF1 0.8659 | Time(s) 1.0316\n",
      "Epoch 00124 | Loss 0.5205 | Test Acc 0.8749 | mF1 0.6776 | wF1 0.8662 | Time(s) 1.0307\n",
      "Epoch 00125 | Loss 0.4665 | Test Acc 0.8500 | mF1 0.6891 | wF1 0.8564 | Time(s) 1.0309\n",
      "Epoch 00126 | Loss 0.5501 | Test Acc 0.8702 | mF1 0.6842 | wF1 0.8649 | Time(s) 1.0308\n",
      "Epoch 00127 | Loss 0.4927 | Test Acc 0.8781 | mF1 0.6534 | wF1 0.8611 | Time(s) 1.0388\n",
      "Epoch 00128 | Loss 0.4428 | Test Acc 0.8762 | mF1 0.6222 | wF1 0.8557 | Time(s) 1.0458\n",
      "Epoch 00129 | Loss 0.5126 | Test Acc 0.8812 | mF1 0.6256 | wF1 0.8605 | Time(s) 1.0534\n",
      "Epoch 00130 | Loss 0.4636 | Test Acc 0.8677 | mF1 0.6197 | wF1 0.8472 | Time(s) 1.0612\n",
      "Epoch 00131 | Loss 0.4560 | Test Acc 0.8598 | mF1 0.6141 | wF1 0.8396 | Time(s) 1.0692\n",
      "Epoch 00132 | Loss 0.4103 | Test Acc 0.8774 | mF1 0.6617 | wF1 0.8614 | Time(s) 1.0772\n",
      "Epoch 00133 | Loss 0.3612 | Test Acc 0.8800 | mF1 0.6903 | wF1 0.8710 | Time(s) 1.0848\n",
      "Epoch 00134 | Loss 0.3577 | Test Acc 0.8620 | mF1 0.6932 | wF1 0.8624 | Time(s) 1.0872\n",
      "Epoch 00135 | Loss 0.4154 | Test Acc 0.8740 | mF1 0.6752 | wF1 0.8618 | Time(s) 1.0859\n",
      "Epoch 00136 | Loss 0.3577 | Test Acc 0.8759 | mF1 0.6325 | wF1 0.8567 | Time(s) 1.0850\n",
      "Epoch 00137 | Loss 0.3538 | Test Acc 0.8809 | mF1 0.6254 | wF1 0.8601 | Time(s) 1.0840\n",
      "Epoch 00138 | Loss 0.3541 | Test Acc 0.8711 | mF1 0.6185 | wF1 0.8504 | Time(s) 1.0834\n",
      "Epoch 00139 | Loss 0.3630 | Test Acc 0.8661 | mF1 0.6042 | wF1 0.8442 | Time(s) 1.0825\n",
      "Epoch 00140 | Loss 0.3749 | Test Acc 0.8730 | mF1 0.6054 | wF1 0.8506 | Time(s) 1.0817\n",
      "Epoch 00141 | Loss 0.3503 | Test Acc 0.8812 | mF1 0.6221 | wF1 0.8601 | Time(s) 1.0805\n",
      "Epoch 00142 | Loss 0.3398 | Test Acc 0.8743 | mF1 0.6174 | wF1 0.8536 | Time(s) 1.0795\n",
      "Epoch 00143 | Loss 0.3896 | Test Acc 0.8768 | mF1 0.6608 | wF1 0.8613 | Time(s) 1.0785\n",
      "Epoch 00144 | Loss 0.3430 | Test Acc 0.8680 | mF1 0.6848 | wF1 0.8631 | Time(s) 1.0773\n",
      "Epoch 00145 | Loss 0.3723 | Test Acc 0.8632 | mF1 0.6718 | wF1 0.8597 | Time(s) 1.0760\n",
      "Epoch 00146 | Loss 0.3728 | Test Acc 0.8809 | mF1 0.6578 | wF1 0.8643 | Time(s) 1.0755\n",
      "Epoch 00147 | Loss 0.3131 | Test Acc 0.8790 | mF1 0.6205 | wF1 0.8577 | Time(s) 1.0752\n",
      "Epoch 00148 | Loss 0.3325 | Test Acc 0.8809 | mF1 0.6182 | wF1 0.8591 | Time(s) 1.0753\n",
      "Epoch 00149 | Loss 0.3486 | Test Acc 0.8806 | mF1 0.6180 | wF1 0.8589 | Time(s) 1.0754\n",
      "Epoch 00150 | Loss 0.3571 | Test Acc 0.8781 | mF1 0.6163 | wF1 0.8566 | Time(s) 1.0776\n",
      "Epoch 00151 | Loss 0.3609 | Test Acc 0.8803 | mF1 0.6178 | wF1 0.8589 | Time(s) 1.0843\n",
      "Epoch 00152 | Loss 0.3350 | Test Acc 0.8797 | mF1 0.6244 | wF1 0.8594 | Time(s) 1.0901\n",
      "Epoch 00153 | Loss 0.3144 | Test Acc 0.8756 | mF1 0.6529 | wF1 0.8596 | Time(s) 1.0898\n",
      "Epoch 00154 | Loss 0.2968 | Test Acc 0.8651 | mF1 0.6614 | wF1 0.8555 | Time(s) 1.0889\n",
      "Epoch 00155 | Loss 0.3079 | Test Acc 0.8566 | mF1 0.6759 | wF1 0.8567 | Time(s) 1.0878\n",
      "Epoch 00156 | Loss 0.3921 | Test Acc 0.8800 | mF1 0.6747 | wF1 0.8680 | Time(s) 1.0872\n",
      "Epoch 00157 | Loss 0.3063 | Test Acc 0.8714 | mF1 0.6324 | wF1 0.8533 | Time(s) 1.0862\n",
      "Epoch 00158 | Loss 0.3487 | Test Acc 0.8727 | mF1 0.6199 | wF1 0.8525 | Time(s) 1.0855\n",
      "Epoch 00159 | Loss 0.3561 | Test Acc 0.8825 | mF1 0.6265 | wF1 0.8618 | Time(s) 1.0848\n",
      "Epoch 00160 | Loss 0.3365 | Test Acc 0.8683 | mF1 0.6165 | wF1 0.8476 | Time(s) 1.0839\n",
      "Epoch 00161 | Loss 0.3422 | Test Acc 0.8468 | mF1 0.6014 | wF1 0.8262 | Time(s) 1.0832\n",
      "Epoch 00162 | Loss 0.4190 | Test Acc 0.8737 | mF1 0.6202 | wF1 0.8530 | Time(s) 1.0825\n",
      "Epoch 00163 | Loss 0.2955 | Test Acc 0.8825 | mF1 0.6401 | wF1 0.8635 | Time(s) 1.0816\n",
      "Epoch 00164 | Loss 0.2902 | Test Acc 0.8803 | mF1 0.6567 | wF1 0.8642 | Time(s) 1.0811\n",
      "Epoch 00165 | Loss 0.3264 | Test Acc 0.8812 | mF1 0.6775 | wF1 0.8685 | Time(s) 1.0801\n",
      "Epoch 00166 | Loss 0.2875 | Test Acc 0.8806 | mF1 0.6852 | wF1 0.8705 | Time(s) 1.0796\n",
      "Epoch 00167 | Loss 0.2886 | Test Acc 0.8733 | mF1 0.6783 | wF1 0.8650 | Time(s) 1.0786\n",
      "Epoch 00168 | Loss 0.3255 | Test Acc 0.8806 | mF1 0.6753 | wF1 0.8671 | Time(s) 1.0780\n",
      "Epoch 00169 | Loss 0.2914 | Test Acc 0.8812 | mF1 0.6516 | wF1 0.8641 | Time(s) 1.0775\n",
      "Epoch 00170 | Loss 0.2969 | Test Acc 0.8860 | mF1 0.6525 | wF1 0.8679 | Time(s) 1.0770\n",
      "Epoch 00171 | Loss 0.2967 | Test Acc 0.8850 | mF1 0.6519 | wF1 0.8670 | Time(s) 1.0765\n",
      "Epoch 00172 | Loss 0.2780 | Test Acc 0.8841 | mF1 0.6628 | wF1 0.8679 | Time(s) 1.0758\n",
      "Epoch 00173 | Loss 0.2947 | Test Acc 0.8816 | mF1 0.6770 | wF1 0.8677 | Time(s) 1.0750\n",
      "Epoch 00174 | Loss 0.2817 | Test Acc 0.8809 | mF1 0.6807 | wF1 0.8681 | Time(s) 1.0744\n",
      "Epoch 00175 | Loss 0.2827 | Test Acc 0.8834 | mF1 0.6827 | wF1 0.8705 | Time(s) 1.0736\n",
      "Epoch 00176 | Loss 0.2818 | Test Acc 0.8831 | mF1 0.6801 | wF1 0.8699 | Time(s) 1.0732\n",
      "Epoch 00177 | Loss 0.2851 | Test Acc 0.8831 | mF1 0.6810 | wF1 0.8696 | Time(s) 1.0727\n",
      "Epoch 00178 | Loss 0.2833 | Test Acc 0.8847 | mF1 0.6815 | wF1 0.8713 | Time(s) 1.0717\n",
      "Epoch 00179 | Loss 0.2710 | Test Acc 0.8841 | mF1 0.6808 | wF1 0.8707 | Time(s) 1.0710\n",
      "Epoch 00180 | Loss 0.2781 | Test Acc 0.8809 | mF1 0.6761 | wF1 0.8673 | Time(s) 1.0702\n",
      "Epoch 00181 | Loss 0.2828 | Test Acc 0.8844 | mF1 0.6735 | wF1 0.8699 | Time(s) 1.0694\n",
      "Epoch 00182 | Loss 0.2768 | Test Acc 0.8869 | mF1 0.6760 | wF1 0.8722 | Time(s) 1.0688\n",
      "Epoch 00183 | Loss 0.2637 | Test Acc 0.8834 | mF1 0.6623 | wF1 0.8674 | Time(s) 1.0682\n",
      "Epoch 00184 | Loss 0.2706 | Test Acc 0.8803 | mF1 0.6573 | wF1 0.8639 | Time(s) 1.0674\n",
      "Epoch 00185 | Loss 0.2606 | Test Acc 0.8812 | mF1 0.6723 | wF1 0.8666 | Time(s) 1.0668\n",
      "Epoch 00186 | Loss 0.2956 | Test Acc 0.8847 | mF1 0.6790 | wF1 0.8709 | Time(s) 1.0666\n",
      "Epoch 00187 | Loss 0.2664 | Test Acc 0.8746 | mF1 0.6744 | wF1 0.8624 | Time(s) 1.0663\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# forward propagation by using all nodes\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# compute loss\u001B[39;00m\n\u001B[0;32m     13\u001B[0m loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mcross_entropy(logits[train_mask]\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat32), node_labels[train_mask]\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mlong))\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\models\\py_gcn.py:113\u001B[0m, in \u001B[0;36mGCN.forward\u001B[1;34m(self, features, g, edge_weight)\u001B[0m\n\u001B[0;32m    111\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    112\u001B[0m         h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(h)\n\u001B[1;32m--> 113\u001B[0m     h \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m h \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mSoftmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)(h) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1e-10\u001B[39m\n\u001B[0;32m    115\u001B[0m h \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlog(h)\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\models\\py_gcn.py:52\u001B[0m, in \u001B[0;36mGraphConvEdgeWeight.forward\u001B[1;34m(self, graph, feat, weight, edge_weights)\u001B[0m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         graph\u001B[38;5;241m.\u001B[39medata[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m edge_weights\n\u001B[1;32m---> 52\u001B[0m         \u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mu_mul_e\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mh\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43ma\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mfn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mh\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m     rst \u001B[38;5;241m=\u001B[39m graph\u001B[38;5;241m.\u001B[39mdstdata[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mh\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;66;03m# aggregate first then mult W\u001B[39;00m\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\dgl\\heterograph.py:5112\u001B[0m, in \u001B[0;36mDGLGraph.update_all\u001B[1;34m(self, message_func, reduce_func, apply_node_func, etype)\u001B[0m\n\u001B[0;32m   5110\u001B[0m _, dtid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_graph\u001B[38;5;241m.\u001B[39mmetagraph\u001B[38;5;241m.\u001B[39mfind_edge(etid)\n\u001B[0;32m   5111\u001B[0m g \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m etype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m[etype]\n\u001B[1;32m-> 5112\u001B[0m ndata \u001B[38;5;241m=\u001B[39m \u001B[43mcore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage_passing\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   5113\u001B[0m \u001B[43m    \u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessage_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapply_node_func\u001B[49m\n\u001B[0;32m   5114\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   5116\u001B[0m     core\u001B[38;5;241m.\u001B[39mis_builtin(reduce_func)\n\u001B[0;32m   5117\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m reduce_func\u001B[38;5;241m.\u001B[39mname \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   5118\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m ndata\n\u001B[0;32m   5119\u001B[0m ):\n\u001B[0;32m   5120\u001B[0m     \u001B[38;5;66;03m# Replace infinity with zero for isolated nodes\u001B[39;00m\n\u001B[0;32m   5121\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ndata\u001B[38;5;241m.\u001B[39mkeys())[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\dgl\\core.py:398\u001B[0m, in \u001B[0;36mmessage_passing\u001B[1;34m(g, mfunc, rfunc, afunc)\u001B[0m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Invoke message passing computation on the whole graph.\u001B[39;00m\n\u001B[0;32m    374\u001B[0m \n\u001B[0;32m    375\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    389\u001B[0m \u001B[38;5;124;03m    Results from the message passing computation.\u001B[39;00m\n\u001B[0;32m    390\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    391\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    392\u001B[0m     is_builtin(mfunc)\n\u001B[0;32m    393\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m is_builtin(rfunc)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    396\u001B[0m ):\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;66;03m# invoke fused message passing\u001B[39;00m\n\u001B[1;32m--> 398\u001B[0m     ndata \u001B[38;5;241m=\u001B[39m \u001B[43minvoke_gspmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;66;03m# invoke message passing in two separate steps\u001B[39;00m\n\u001B[0;32m    401\u001B[0m     \u001B[38;5;66;03m# message phase\u001B[39;00m\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_builtin(mfunc):\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\dgl\\core.py:359\u001B[0m, in \u001B[0;36minvoke_gspmm\u001B[1;34m(graph, mfunc, rfunc, srcdata, dstdata, edata)\u001B[0m\n\u001B[0;32m    357\u001B[0m         x \u001B[38;5;241m=\u001B[39m data_dict_to_list(graph, x, mfunc, lhs_target)\n\u001B[0;32m    358\u001B[0m         y \u001B[38;5;241m=\u001B[39m data_dict_to_list(graph, y, mfunc, rhs_target)\n\u001B[1;32m--> 359\u001B[0m     z \u001B[38;5;241m=\u001B[39m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    361\u001B[0m     x \u001B[38;5;241m=\u001B[39m alldata[mfunc\u001B[38;5;241m.\u001B[39mtarget][mfunc\u001B[38;5;241m.\u001B[39min_field]\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\dgl\\ops\\spmm.py:173\u001B[0m, in \u001B[0;36m_gen_spmm_func.<locals>.func\u001B[1;34m(g, x, y)\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfunc\u001B[39m(g, x, y):\n\u001B[1;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgspmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbinary_op\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce_op\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\dgl\\ops\\spmm.py:79\u001B[0m, in \u001B[0;36mgspmm\u001B[1;34m(g, op, reduce_op, lhs_data, rhs_data)\u001B[0m\n\u001B[0;32m     77\u001B[0m         lhs_data, rhs_data \u001B[38;5;241m=\u001B[39m reshape_lhs_rhs(lhs_data, rhs_data)\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;66;03m# With max and min reducers infinity will be returned for zero degree nodes\u001B[39;00m\n\u001B[1;32m---> 79\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mgspmm_internal\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[43m        \u001B[49m\u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mreduce_op\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmean\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mreduce_op\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlhs_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrhs_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     85\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;66;03m# lhs_data or rhs_data is None only in unary functions like ``copy-u`` or ``copy_e``\u001B[39;00m\n\u001B[0;32m     88\u001B[0m     lhs_data \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     89\u001B[0m         [\u001B[38;5;28;01mNone\u001B[39;00m] \u001B[38;5;241m*\u001B[39m g\u001B[38;5;241m.\u001B[39m_graph\u001B[38;5;241m.\u001B[39mnumber_of_ntypes()\n\u001B[0;32m     90\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m lhs_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     91\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m lhs_data\n\u001B[0;32m     92\u001B[0m     )\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\dgl\\backend\\pytorch\\sparse.py:1032\u001B[0m, in \u001B[0;36mgspmm\u001B[1;34m(gidx, op, reduce_op, lhs_data, rhs_data)\u001B[0m\n\u001B[0;32m   1030\u001B[0m args \u001B[38;5;241m=\u001B[39m _cast_if_autocast_enabled(gidx, op, reduce_op, lhs_data, rhs_data)\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _disable_autocast_if_enabled():\n\u001B[1;32m-> 1032\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mGSpMM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\torch\\autograd\\function.py:598\u001B[0m, in \u001B[0;36mFunction.apply\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m    595\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_are_functorch_transforms_active():\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001B[39;00m\n\u001B[0;32m    597\u001B[0m     args \u001B[38;5;241m=\u001B[39m _functorch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39munwrap_dead_wrappers(args)\n\u001B[1;32m--> 598\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m    600\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_setup_ctx_defined:\n\u001B[0;32m    601\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    602\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn order to use an autograd.Function with functorch transforms \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    603\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    604\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstaticmethod. For more details, please see \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    605\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    606\u001B[0m     )\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\dgl\\backend\\pytorch\\sparse.py:165\u001B[0m, in \u001B[0;36mGSpMM.forward\u001B[1;34m(ctx, gidx, op, reduce_op, X, Y)\u001B[0m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(ctx, gidx, op, reduce_op, X, Y):\n\u001B[1;32m--> 165\u001B[0m     out, (argX, argY) \u001B[38;5;241m=\u001B[39m \u001B[43m_gspmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgidx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce_op\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m     reduce_last \u001B[38;5;241m=\u001B[39m _need_reduce_last_dim(X, Y)\n\u001B[0;32m    167\u001B[0m     X_shape \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\dgl\\_sparse_ops.py:239\u001B[0m, in \u001B[0;36m_gspmm\u001B[1;34m(gidx, op, reduce_op, u, e)\u001B[0m\n\u001B[0;32m    237\u001B[0m arg_e_nd \u001B[38;5;241m=\u001B[39m to_dgl_nd_for_write(arg_e)\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gidx\u001B[38;5;241m.\u001B[39mnum_edges(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 239\u001B[0m     \u001B[43m_CAPI_DGLKernelSpMM\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    240\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgidx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    241\u001B[0m \u001B[43m        \u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    242\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreduce_op\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mto_dgl_nd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43muse_u\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    244\u001B[0m \u001B[43m        \u001B[49m\u001B[43mto_dgl_nd\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43muse_e\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    245\u001B[0m \u001B[43m        \u001B[49m\u001B[43mto_dgl_nd_for_write\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    246\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_u_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    247\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_e_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    248\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# NOTE(zihao): actually we can avoid the following step, because arg_*_nd\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# refers to the data that stores arg_*. After we call _CAPI_DGLKernelSpMM,\u001B[39;00m\n\u001B[0;32m    251\u001B[0m \u001B[38;5;66;03m# arg_* should have already been changed. But we found this doesn't work\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    254\u001B[0m \u001B[38;5;66;03m# The workaround is proposed by Jinjing, and we still need to investigate\u001B[39;00m\n\u001B[0;32m    255\u001B[0m \u001B[38;5;66;03m# where the problem is.\u001B[39;00m\n\u001B[0;32m    256\u001B[0m arg_u \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m arg_u \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m F\u001B[38;5;241m.\u001B[39mzerocopy_from_dgl_ndarray(arg_u_nd)\n",
      "File \u001B[1;32mD:\\nguyennha\\TextGraph\\.venv\\Lib\\site-packages\\dgl\\_ffi\\_ctypes\\function.py:213\u001B[0m, in \u001B[0;36mFunctionBase.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    210\u001B[0m ret_val \u001B[38;5;241m=\u001B[39m DGLValue()\n\u001B[0;32m    211\u001B[0m ret_tcode \u001B[38;5;241m=\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mc_int()\n\u001B[0;32m    212\u001B[0m check_call(\n\u001B[1;32m--> 213\u001B[0m     \u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDGLFuncCall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtcodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_args\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mret_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    219\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mret_tcode\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    220\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    221\u001B[0m )\n\u001B[0;32m    222\u001B[0m _ \u001B[38;5;241m=\u001B[39m temp_args\n\u001B[0;32m    223\u001B[0m _ \u001B[38;5;241m=\u001B[39m args\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T19:10:15.608793Z",
     "start_time": "2025-03-28T19:10:15.607796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Max accuracy: {max_acc:.4f}\")\n",
    "print(f'Max F1: {max_f1:.4f}')"
   ],
   "id": "c8a1025c26b6bf51",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
